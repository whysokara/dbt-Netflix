# dbt-Netflix

# ğŸ¬ Netflix Analytics with dbt

This is a **dbt (data build tool)** project that models and analyzes movie ratings and tag data to simulate Netflix-style analytics. The project demonstrates a modern data stack workflow â€” from ingestion to transformation to analysis.

---

## ğŸ›  Project Overview

This project simulates a real-world analytics pipeline for Netflix-style movie data by:

- ğŸ“¥ Ingesting public data from a **mock API**
- ğŸª£ Uploading the data to an **Amazon S3 bucket**
- â„ï¸ Using **Snowflakeâ€™s external stage and file format** to load data from S3
- ğŸ§± Transforming raw data into trusted models using **dbt**
- ğŸ“Š Building dimensional models, fact tables, and reporting marts

---

## ğŸ“‚ Project Structure

```bash
models/
â”œâ”€â”€ schema.yml                 # Global tests and docs
â”œâ”€â”€ staging/                   # Source-level cleaning & typing
â”‚   â”œâ”€â”€ source.yml             # dbt source configs
â”‚   â”œâ”€â”€ src_genome_scores.sql
â”‚   â”œâ”€â”€ src_movies.sql
â”‚   â”œâ”€â”€ src_tags.sql
â”‚   â”œâ”€â”€ src_ratings.sql
â”‚   â””â”€â”€ ...
â”œâ”€â”€ dim/                       # Dimension models (slow-changing, descriptive)
â”‚   â”œâ”€â”€ dim_users.sql
â”‚   â”œâ”€â”€ dim_genome_tags.sql
â”‚   â””â”€â”€ dim_movies.sql
â”œâ”€â”€ fct/                       # Fact models (event and transaction tables)
â”‚   â”œâ”€â”€ fct_ratings.sql
â”‚   â””â”€â”€ fct_genome_scores.sql
â””â”€â”€ mart/                      # Business-facing aggregated outputs
    â””â”€â”€ mart_movie_releases.sql

Data Flow

ğŸ“¡ Data Collection: Used mock movie & ratings data from a public API (e.g. Kaggle or open datasets).
ğŸ“¤ Data Upload: Uploaded the raw CSV/JSON files into an S3 bucket.
â„ï¸ Snowflake Load: Used Snowflake external stage, file format, and COPY INTO to load data from S3 into Snowflake raw tables.
âš™ï¸ dbt Transformation:
Created staging models to clean and format raw data
Created dim and fct models to build a star schema
Added mart models to support business insights

ğŸ§  Key Features

ğŸ”§ dbt-based data transformation from raw S3 â†’ Snowflake â†’ Trusted models
ğŸ§± Star schema with dimension and fact models
ğŸ§ª Robust testing: not_null, unique, relationships
ğŸ” Surrogate key generation using dbt_utils.generate_surrogate_key
ğŸ“Š Aggregated movie ratings and tag relevance scores
ğŸ“„ Descriptions + schema documentation for all models and columns

 How to Run

ğŸ“¦ Requirements
Python + Virtualenv or Conda
dbt v1.10+ (dbt-snowflake)
Access to Snowflake & S3
ğŸ”§ Setup Instructions
# 1. Clone the repo
git clone https://github.com/<your-username>/netflix-dbt.git
cd netflix-dbt

# 2. Set up virtual environment
python -m venv venv
source venv/bin/activate

# 3. Install dbt for Snowflake
pip install dbt-snowflake

# 4. Install packages
dbt deps

# 5. Configure your Snowflake profile (~/.dbt/profiles.yml)
ğŸš€ Run dbt Commands
# Check connection
dbt debug

# Run transformations
dbt run

# Run tests
dbt test

# Generate and view documentation
dbt docs generate
dbt docs serve
ğŸ“Š Sample SQL Output: Top 20 Rated Movies

WITH ratings_summary AS (
    SELECT
        movie_id,
        AVG(rating) AS average_rating,
        COUNT(*) AS total_ratings
    FROM {{ ref('fct_ratings') }}
    GROUP BY movie_id
    HAVING COUNT(*) > 100
)

SELECT
    m.movie_title,
    rs.average_rating,
    rs.total_ratings
FROM ratings_summary rs
JOIN {{ ref('dim_movies') }} m ON rs.movie_id = m.movie_id
ORDER BY rs.average_rating DESC
LIMIT 20;
ğŸ“¦ Packages Used

dbt-utils â€” for reusable macros like generate_surrogate_key
snowflake adapter â€” for data warehousing
âœ… Tests Included

not_null and unique for primary keys
relationships between fact & dimension tables
Custom macro to check for nulls across columns:
{% macro no_nulls_in_columns(model) %}
  SELECT * FROM {{ model }} WHERE
  {% for col in adapter.dbt_utils.get_filtered_columns_in_relation(model) %}
    {{ col.column }} IS NULL OR
  {% endfor %}
  FALSE
{% endmacro %}
